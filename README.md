# ğŸ§  Uncertainty-Aware and Noise-Resilient Task-Oriented Semantic Communication (TOSC)

This repository contains a **minimal simulation framework** for studying how *uncertainty-aware transmission* and *semantic robustness* can be modeled in **AI-native communication systems**.  
The implementation combines pretrained **Variational Autoencoders (VAEs)** for image encoding and **Vision-Language Models (CLIP)** for semantic evaluation, allowing the simulation of noisy semantic channels and adaptive transmission decisions.

---

## ğŸ“– Overview

The pipeline demonstrates a simplified version of the semantic communication loop proposed in recent 6G AI-RAN research:

1. **Semantic Encoding (VAE):**  
   Images are encoded into latent vectors `z`, which serve as compressed semantic representations.

2. **Channel Simulation:**  
   Additive White Gaussian Noise (AWGN), quantization, and dropout are applied to `z` to emulate physical-layer degradation.

3. **Semantic Evaluation (CLIP):**  
   CLIP embeddings quantify the similarity between the original image and reconstructed outputs, measuring *semantic fidelity* rather than pixel accuracy.

4. **Uncertainty-Aware Transmission Gate:**  
   A confidence-based rule decides whether to transmit through the channel.  
   If the uncertainty `u = 1 âˆ’ similarity` exceeds a threshold `Ï„`, transmission is triggered; otherwise, it is skipped to save bandwidth.

The project follows the structure below:

```
semantic-channel-modeling/
â”‚
â”œâ”€â”€ semcom_main.py          # Main demo script
â”œâ”€â”€ semcom_utils.py         # Utility functions (VAE, CLIP, channel, etc.)
â”œâ”€â”€ experiments/            # Experimental scripts
â”‚   â”œâ”€â”€ exp_quantization_noise.py      # Exp1: Quantization & noise
â”‚   â”œâ”€â”€ exp_tau_scan.py                # Exp2: Tau threshold scan
â”‚   â”œâ”€â”€ exp_sigma_tau_joint.py         # Exp3: SigmaÃ—Tau joint (recommended)
â”‚   â”œâ”€â”€ exp_complexity_robustness.py   # Exp4: Image complexity robustness
â”‚   â”œâ”€â”€ exp_quick_test.py              # Quick test script
â”‚   â””â”€â”€ README.md                      # Experiments guide
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ USAGE_GUIDE.md             # Installation & usage guide
â”‚   â”œâ”€â”€ EXP1_RESULTS.md            # Experiment 1 results
â”‚   â”œâ”€â”€ EXP2_RESULTS.md            # Experiment 2 results
â”‚   â”œâ”€â”€ EXP3_RESULTS.md            # Experiment 3 results
â”‚   â””â”€â”€ EXP4_RESULTS.md            # Experiment 4 results
â”œâ”€â”€ data/                   # Input images directory
â”‚   â””â”€â”€ all_images/        # Test image dataset (150 images)
â”œâ”€â”€ results/                # Experimental results
â”‚   â”œâ”€â”€ *.csv              # Data tables
â”‚   â””â”€â”€ plots/             # Visualization plots
â”œâ”€â”€ out_demo/               # Demo output images
â””â”€â”€ requirements.txt        # Python dependencies
```

---

## ğŸ“š Documentation

- **[Usage Guide](docs/USAGE_GUIDE.md)** - Installation, quick start, troubleshooting
- **[Experiments Guide](experiments/README.md)** - Experimental scripts details

### ğŸ“Š Experimental Results
- **[Experiment 1: Quantization & Noise](docs/EXP1_RESULTS.md)** - Rate-distortion analysis, 6-bit optimal finding
- **[Experiment 2: Tau Threshold Scan](docs/EXP2_RESULTS.md)** - Uncertainty threshold optimization, 17% quality gain
- **[Experiment 3: SigmaÃ—Tau Joint](docs/EXP3_RESULTS.md)** - Channel-adaptive transmission strategy (recommended)
- **[Experiment 4: Image Complexity Robustness](docs/EXP4_RESULTS.md)** - Content-aware robustness analysis, "Goldilocks Zone" discovery

---

## ğŸ§© Features

- âœ… Pretrained **Stable Diffusion VAE** for latent-space encoding  
- âœ… Pretrained **OpenCLIP (ViT-B/32)** for semantic similarity evaluation  
- âœ… Configurable **noise, quantization, and dropout** parameters  
- âœ… Adaptive **uncertainty-based transmission gate**  
- âœ… Modular, research-ready structure (easy to extend for BLIP, multi-image, or text-conditioned setups)

---

## âš™ï¸ Installation

### 1. Clone the repository
```bash
git clone https://github.com/<yourusername>/semantic-channel-modeling.git
cd semantic-channel-modeling
```

### 2. Create and activate a virtual environment
**Windows (PowerShell):**
```bash
python -m venv .venv
.venv\Scripts\activate
```

**macOS / Linux:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

> âš ï¸ Note: for faster model loading, it is recommended to install:
> ```bash
> pip install accelerate hf_xet
> ```
> (optional, improves performance when downloading Hugging Face weights)

---

## ğŸ§ª Running the Simulation

To execute the experiment with default settings:

```bash
python semcom_main.py
```

Expected console output:
```
{'transmit': False, 'sim_local': 0.9783, 'sim_rx': 0.9783, 'uncertainty': 0.0216}
Images saved in: out_demo/
```

### Output Files (in `out_demo/`)
| File | Description |
|------|--------------|
| `input_resized.png` | Original resized input image |
| `recon_baseline.png` | Local VAE reconstruction (no channel) |
| `recon_rx.png` | Reconstruction after channel corruption *(only if transmitted)* |

---

## ğŸ§® Key Parameters

| Parameter | Description | Default |
|------------|--------------|----------|
| `SIGMA` | Standard deviation of AWGN noise | `0.10` |
| `N_BITS` | Quantization bit-depth | `6` |
| `DROPOUT_P` | Dropout probability on latent vector | `0.00` |
| `TAU` | Transmission threshold for uncertainty gating | `0.02` |
| `SIZE_VAE` | Input image resolution for VAE | `512 Ã— 512` |

---

## ğŸ§  Conceptual Diagram

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚        Input Image        â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              [ Semantic Encoder (VAE) ]
                        â”‚
                        â–¼
               Latent Representation z
                        â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚                     â”‚
     Low Uncertainty         High Uncertainty
    (skip transmission)        (transmit zâ†’channel)
             â”‚                     â”‚
             â–¼                     â–¼
   Local reconstruction     Channel corruption + decode
             â”‚                     â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
              [ Semantic Evaluator (CLIP) ]
                        â”‚
                        â–¼
           Semantic Similarity & Uncertainty Metric
```

---

## ğŸ“Š Example Interpretation

| Metric | Meaning |
|---------|----------|
| `sim_local` | CLIP cosine similarity before transmission |
| `uncertainty` | `1 - sim_local`; low means high confidence |
| `transmit` | `True` if uncertainty > Ï„ (channel used) |
| `sim_rx` | Semantic similarity after noisy transmission |

---

## ğŸ“š References

- GÃ¼ndÃ¼z, D., Quek, T. Q. S., Strinati, E. C., & Kim, S.-L. (2022). *Beyond transmitting bits: Context, semantics, and task-oriented communications.*  
  [arXiv:2207.09353](https://discovery.ucl.ac.uk/10162483/1/Semantic_JSAC_SI_submitted.pdf)

- Oh, S., Kim, J., Park, J., Ko, S.-W., Quek, T. Q. S., & Kim, S.-L. (2025). *Uncertainty-aware hybrid inference with on-device small and remote large language models.*  
  IEEE ICMLCN. [link](https://ieeexplore.ieee.org/abstract/document/10508293)

- Liu, X., Zhang, Y., Zhou, F., & Zhang, H. (2022). *Task-oriented image semantic communication based on rate-distortion theory.*  
  [arXiv:2201.10929](https://arxiv.org/abs/2201.10929)

- Strinati, E. C., et al. (2024). *Goal-oriented and semantic communication in 6G AI-native networks: The 6G-GOALS approach.*  
  [arXiv:2402.07573](https://arxiv.org/abs/2402.07573)

---

## ğŸ§© License

This work is provided for **academic and research purposes only**.  
