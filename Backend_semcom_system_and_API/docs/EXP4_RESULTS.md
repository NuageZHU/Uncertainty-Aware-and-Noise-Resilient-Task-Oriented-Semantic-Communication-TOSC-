````markdown
# Experiment 4 Results: Semantic Robustness vs Image Complexity

## ğŸ“Š Setup

Fixed:
- Quantization: `n_bits = 6` (best from Exp1)
- Noise: `sigma = 0.1` (medium channel)
- Transmit threshold: `tau = 0.05` (moderate policy)
- Images: 150 under `data/all_images/`

Whatâ€™s new:
- Group by image statistics (not human categories)
- Complexity metrics via OpenCV + FFT
- Study how content complexity affects robustness

Complexity metrics:
1) Edge density â€” Canny edges, normalized to [0,1]
2) Color variance â€” mean std over RGB channels
3) High-frequency ratio â€” FFT magnitude outside a radius
4) Combined score â€” weighted average (edges 50% + color 30% + HF 20%)

Grouping:
- Low: < 33rd percentile (score < 0.314)
- Medium: 33rdâ€“67th (0.314 â‰¤ score < 0.374)
- High: > 67th (score â‰¥ 0.374)

---

## ğŸ“ˆ Core Results

### 1) Group statistics

| Group | N | Mean score | Range |
|-------|---|------------|-------|
| Low   | 50 | 0.264 | < 0.314 |
| Medium| 50 | 0.344 | 0.314â€“0.374 |
| High  | 50 | 0.413 | â‰¥ 0.374 |

Balanced splits (50/50/50) with clear score separation (â‰ˆ0.07â€“0.08).

### 2) Semantic quality by complexity

| Group | sim_local | sim_rx | effective_sim | degradation | transmit_rate |
|-------|-----------|--------|---------------|-------------|----------------|
| Low   | 0.905 | 0.817 | 0.817 | 0.088 | 62% |
| Medium| 0.919 | 0.846 | 0.846 | 0.072 | 62% |
| High  | 0.911 | 0.830 | 0.830 | 0.081 | 80% |

Finding 1 â€” Medium complexity performs best:
```
sim_rx (medium) = 0.846
vs low:  +3.5%
vs high: +1.9%
```

Why:
- Low complexity (e.g., flat backgrounds):
  - sim_local is high but semantic content is sparse; CLIP separability is low
  - small perturbations disrupt the few semantic cues
- Medium complexity (e.g., scenes):
  - rich semantics without overloading the representation
  - VAE encodes efficiently â†’ best semanticâ€“compression balance â­
- High complexity (e.g., text/texture):
  - many high-frequency details â†’ harder to encode; quantization errors cumulate
  - channel noise harms details more

Finding 2 â€” U-shaped degradation vs complexity:
```
Low:    0.088 (highest)
Medium: 0.072 (lowest) â­
High:   0.081 (middle)
```
Medium is significantly better than low (âˆ’18.2%) and high (âˆ’11.1%).

Finding 3 â€” Transmit rate reflects content:

| Group | T-rate | Uncertainty | Policy |
|-------|--------|-------------|--------|
| Low/Medium | 62% | Medium | Moderate filtering |
| High       | 80% | Higher | Aggressive transmit |

Interpretation: High-complexity images yield lower sim_local (higher uncertainty), triggering more transmissions â€” but with Ïƒ=0.1 this often does not improve quality. Suggest higher Ï„ for high complexity (more conservative transmit).

### 3) Local reconstruction quality

| Group | sim_local | vs Medium |
|-------|-----------|-----------|
| Low   | 0.905 | âˆ’1.5% |
| Medium| 0.919 | Baseline â­ |
| High  | 0.911 | âˆ’0.9% |

Medium also wins locally.

Reasons:
1) VAE training bias: SD-VAE is trained on natural images; medium complexity (objects/scenes) matches training distribution best.
2) CLIP perception: CLIP is strong on mid-level semantics (objects, scenes, actions), less on low-level color blocks and ultra-fine textural details.

---

## ğŸ’¡ Insights

### Insight 1: â€œGoldilocks Zoneâ€

Like the habitable zone in cosmology â€” mid complexity is â€œjust rightâ€.

Characteristics:
- Combined score: 0.31â€“0.37
- Edge density: 0.25â€“0.35
- Color variance: 40â€“60
- High-frequency ratio: 0.15â€“0.25

Applications:
- Predict transmit quality at capture time
- Adapt encoding params by complexity
- Prioritize/queue â€œGoldilocksâ€ content

### Insight 2: The complexityâ€“robustness paradox

Conventional wisdom: simpler â†’ easier to encode â†’ more robust.

Here: Medium > Low > High.

Explanation:

| Factor | Low | Medium | High |
|--------|-----|--------|------|
| Semantic redundancy | Low âš ï¸ | High âœ“ | Medium |
| Encoding efficiency  | Medium | High âœ“ | Low âš ï¸ |
| Noise resilience     | Low âš ï¸ | High âœ“ | Medium |
| CLIP separability    | Low âš ï¸ | High âœ“ | Medium |

Semantic redundancy is key. Low complexity lacks redundancy; high complexity overloads representation; medium complexity balances both.

### Insight 3: Link to Exp1 â€” content-aware n_bits

Exp1: 6-bit best on average. Exp4: different complexities may prefer different n_bits.

Hypothesis:
```python
if complexity_score < 0.31:
    n_bits = 4  # low complexity â†’ fewer bits
elif complexity_score < 0.37:
    n_bits = 6  # medium â†’ default best
else:
    n_bits = 8  # high complexity â†’ more bits for details
```

Potential gains:
- Low: save ~33% bandwidth
- High: +2â€“3% quality
- Medium: keep 6-bit

Validate via per-group quantization sweeps.

### Insight 4: Content-aware Ï„

Current: Ï„=0.05 for all.

Observed: High has higher T-rate (80%) than Low/Medium (62%), yet not higher quality.

Improve:
```python
if complexity_score < 0.31:
    tau = 0.03
elif complexity_score < 0.37:
    tau = 0.05
else:
    tau = 0.10  # more conservative
```

Expected:
- High: T-rate down to ~50â€“60%
- Preserve more good local reconstructions
- +2â€“5% overall sim_rx

---

## ğŸ”¬ Technical Details

### Complexity computation

1) Edge density (Canny):
```python
edges = cv2.Canny(img_gray, threshold1=50, threshold2=150)
edge_density = edges.mean() / 255.0
```
Meaning: [0,1]; higher â†’ more structure (buildings, text).
Weight: 50%.

2) Color variance (RGB std mean):
```python
color_variance = img_rgb.std(axis=(0, 1)).mean()
```
Higher â†’ more varied colors; lower â†’ flat palettes. Weight: 30%.

3) High-frequency ratio (FFT):
```python
fft = np.fft.fft2(img_gray)
fft_shift = np.fft.fftshift(fft)
magnitude = np.abs(fft_shift)
mask = distance_from_center > radius
high_freq_ratio = magnitude[mask].sum() / magnitude.sum()
```
Higher â†’ more textures/noise; lower â†’ smoother fields. Weight: 20%.

Combined score:
```python
complexity_score = 0.5*edge_density + 0.3*(color_variance/100) + 0.2*high_freq_ratio
```

---

## ğŸ“Š Plots

### 1) complexity_distribution.png (4 subplots)

(a) Combined score distribution: three peaks for low/medium/high.
- Low: 0.2â€“0.3, tight variance
- Medium: 0.3â€“0.37
- High: 0.37â€“0.5, broader tail

(b) Edge density distribution: strongest separator (low < 0.2, high > 0.3).

(c) Color variance: overlapping but with a higher tail for high.

(d) HF ratio: smaller differences; weakest separator (hence 20% weight).

### 2) complexity_robustness_bar.png (4 subplots)

(a) Semantic quality bars (Local / After channel / Effective). Medium has the tallest â€œafter channelâ€ bar (0.846); low is lowest (0.817). Effective equals after-channel since T-rate > 0.

(b) Semantic degradation bars: U-shape (Low 0.088, Medium 0.072, High 0.081).

(c) Transmit rate bars: Low/Medium â‰ˆ 62%, High â‰ˆ 80%.

(d) Complexity score bars: 0.26 â†’ 0.34 â†’ 0.41.

### 3) complexity_vs_performance.png (2 subplots)

Left: complexity vs `sim_rx` (scatter + trend). Medium points are higher overall; slight negative slope (~âˆ’0.05).

Right: complexity vs `semantic_degradation` (scatter + trend). U-shape visible: high at low complexity, lowest at medium, rises at high.

---

## ğŸ¯ Limitations

1) Single Ïƒ (0.1). Generalization to other channels is untested here. Extend to sigma Ã— complexity.

2) Fixed Ï„ (0.05) for all. High complexity may need higher Ï„; low may accept lower Ï„. Try content-aware Ï„.

3) Percentile-based grouping (33/67) is heuristic. Alternatives: k-means, decision trees, GMM.

4) Metric coverage: current metrics are low-level. Add semantic-level complexity (object count, scene class), structural features (orientation), richer frequency descriptors, or learned complexity.

---

## ğŸš€ Suggested Extensions

E1) Complexity-adaptive quantization
```python
COMPLEXITY_GROUPS = ['low', 'medium', 'high']
QUANTIZATION_LEVELS = {
    'low': [2, 4, 6],
    'medium': [4, 6, 8],
    'high': [6, 8, 12]
}
```
Expect: lowâ†’4-bit may suffice; mediumâ†’6-bit; highâ†’8-bit helps.

E2) Complexity-adaptive Ï„
```python
TAU_BY_COMPLEXITY = {
    'low': [0.02, 0.05, 0.08],
    'medium': [0.03, 0.05, 0.10],
    'high': [0.05, 0.10, 0.15, 0.20]
}
```
Find Ï„* per group.

E3) Multi-channel robustness (Ïƒ Ã— complexity Ã— Ï„). 5 Ã— 3 Ã— 4 = 60 configs. Output: global optimal map.

E4) Learned complexity predictor (e.g., ResNet-18 â†’ FC â†’ score). Train on current 150 images with computed scores to enable real-time adaptation.

---

## ğŸ“ Conclusions

1) Medium complexity is most robust â­â­â­
```
sim_rx (medium) = 0.846
vs low +3.5%, vs high +1.9%
Lowest degradation: 0.072 (âˆ’18% vs low)
```

2) U-shaped complexityâ€“robustness relation
```
Degradation: low 0.088, medium 0.072 (best), high 0.081
```

Practice:
- Capture: favor medium complexity scenes
- Prioritization: Medium > Low > High
- Prediction: complexity helps forecast transmit quality

Theory:
- Challenges â€œsimple = robustâ€
- Semantic redundancy > mere encoding simplicity
````
- ä¸­ç­‰å¤æ‚åº¦æ˜¯"ç”œèœœç‚¹"

---

#### ç»“è®º3ï¼šä¼ è¾“ç­–ç•¥åº”å†…å®¹æ„ŸçŸ¥

```
å½“å‰ï¼ˆå›ºå®š Ï„=0.05ï¼‰ï¼š
  ä½/ä¸­ä¼ è¾“ç‡ï¼š62%
  é«˜ä¼ è¾“ç‡ï¼š80%ï¼ˆä½†æ•ˆæœä¸ä½³ï¼‰

ä¼˜åŒ–ï¼ˆè‡ªé€‚åº” Ï„ï¼‰ï¼š
  é«˜å¤æ‚åº¦ç”¨ Ï„=0.10
  é¢„è®¡ä¼ è¾“ç‡é™è‡³ 50-60%
  è´¨é‡æå‡ 2-5%
```

---

#### ç»“è®º4ï¼šä¸å®éªŒ1/2/3çš„ååŒæ•ˆåº”

**å¤šç»´ä¼˜åŒ–ç©ºé—´ï¼š**
```
å®éªŒ1ï¼šn_bits = 6ï¼ˆæœ€ä¼˜é‡åŒ–ï¼‰
å®éªŒ2ï¼štau = 0.08-0.20ï¼ˆæœ€ä¼˜é˜ˆå€¼ï¼Œä¾ä¿¡é“ï¼‰
å®éªŒ3ï¼šsigma-tau è”åˆä¼˜åŒ–
å®éªŒ4ï¼šcomplexity-aware ç­–ç•¥

è”åˆä¼˜åŒ–æ½œåŠ›ï¼š
  åŸºå‡†ï¼ˆn_bits=6, sigma=0.1, tau=0.05ï¼‰ï¼š0.817
  + å®éªŒ2ä¼˜åŒ–ï¼ˆtau=0.15ï¼‰ï¼š+7%
  + å®éªŒ4ä¼˜åŒ–ï¼ˆå†…å®¹æ„ŸçŸ¥ï¼‰ï¼š+2-3%
  æ€»æå‡ï¼š9-10%
```

---

## ğŸ“ å­¦æœ¯è´¡çŒ®

### è´¡çŒ®1ï¼šé¦–æ¬¡é‡åŒ–å›¾åƒå¤æ‚åº¦ä¸è¯­ä¹‰é²æ£’æ€§å…³ç³»

**åˆ›æ–°ç‚¹ï¼š**
- ä¸ä¾èµ–äººå·¥æ ‡æ³¨ç±»åˆ«
- åŸºäºåº•å±‚ç»Ÿè®¡ç‰¹æ€§è‡ªåŠ¨åˆ†ç»„
- å‘ç°"é‡‘å‘å¥³å­©åŒºé—´"ç°è±¡

**å½±å“ï¼š**
- å¯æŒ‡å¯¼å†…å®¹æ„ŸçŸ¥çš„è¯­ä¹‰é€šä¿¡ç³»ç»Ÿè®¾è®¡
- ä¸ºè‡ªé€‚åº”ç¼–ç æä¾›ç†è®ºä¾æ®

---

### è´¡çŒ®2ï¼šæŒ‘æˆ˜ä¼ ç»Ÿ"ç®€å•=é²æ£’"å‡è®¾

**ä¼ ç»Ÿè§‚ç‚¹ï¼š** ç®€å•å†…å®¹ â†’ å®¹æ˜“å‹ç¼© â†’ é²æ£’æ€§é«˜

**æœ¬ç ”ç©¶å‘ç°ï¼š** ä¸­ç­‰å¤æ‚åº¦ > ä½å¤æ‚åº¦

**æ–°è§†è§’ï¼š** è¯­ä¹‰å†—ä½™åº¦æ˜¯é²æ£’æ€§çš„æ ¸å¿ƒ

---

### è´¡çŒ®3ï¼šæå‡ºå†…å®¹æ„ŸçŸ¥ä¼ è¾“ç­–ç•¥

**ä¼ ç»Ÿæ–¹æ³•ï¼š** ç»Ÿä¸€ Ï„ å¯¹æ‰€æœ‰å†…å®¹

**æœ¬ç ”ç©¶å»ºè®®ï¼š** æ ¹æ®å¤æ‚åº¦è‡ªé€‚åº”è°ƒæ•´ Ï„

**æ½œåœ¨æ”¶ç›Šï¼š** 2-5% è´¨é‡æå‡ï¼Œå‡å°‘ 10-20% æ— æ•ˆä¼ è¾“

---

## ğŸ“Š æ•°æ®æ–‡ä»¶è¯´æ˜

### CSVæ–‡ä»¶ç»“æ„

#### complexity_robustness_detail.csvï¼ˆ150 è¡Œï¼‰

| åˆ—å | è¯´æ˜ | èŒƒå›´ |
|------|------|------|
| img_name | å›¾åƒæ–‡ä»¶å | - |
| complexity_group | å¤æ‚åº¦åˆ†ç»„ | [low, medium, high] |
| edge_density | è¾¹ç¼˜å¯†åº¦ | [0, 1] |
| color_variance | é¢œè‰²æ–¹å·® | [0, ~100] |
| high_freq_ratio | é«˜é¢‘å æ¯” | [0, 1] |
| complexity_score | ç»¼åˆå¾—åˆ† | [0, 1] |
| sim_local | æœ¬åœ°é‡å»ºç›¸ä¼¼åº¦ | [0, 1] |
| sim_rx | ä¿¡é“åç›¸ä¼¼åº¦ | [0, 1] |
| transmit | æ˜¯å¦ä¼ è¾“ | True/False |
| uncertainty | ä¸ç¡®å®šæ€§ | [0, 1] |
| effective_sim | æœ‰æ•ˆç›¸ä¼¼åº¦ | [0, 1] |
| semantic_degradation | è¯­ä¹‰é€€åŒ– | [0, 1] |

---

#### complexity_robustness_results.csvï¼ˆ3 è¡Œï¼‰

**èšåˆç»Ÿè®¡ï¼š** æ¯è¡Œå¯¹åº”ä¸€ä¸ªå¤æ‚åº¦ç»„

| åˆ—å | è¯´æ˜ |
|------|------|
| complexity_group | ç»„å |
| n_samples | æ ·æœ¬æ•° |
| complexity_score | å¹³å‡å¤æ‚åº¦å¾—åˆ† |
| sim_local | å¹³å‡æœ¬åœ°ç›¸ä¼¼åº¦ |
| sim_rx | å¹³å‡ä¼ è¾“ç›¸ä¼¼åº¦ |
| effective_sim | å¹³å‡æœ‰æ•ˆç›¸ä¼¼åº¦ |
| transmit_rate | ä¼ è¾“ç‡ |
| semantic_degradation | å¹³å‡è¯­ä¹‰é€€åŒ– |

---

### å›¾è¡¨æ–‡ä»¶ï¼ˆ3 ç»„ï¼‰

1. **complexity_distribution.png**
   - 4 å­å›¾ï¼šå¤æ‚åº¦å¾—åˆ†ã€è¾¹ç¼˜å¯†åº¦ã€é¢œè‰²æ–¹å·®ã€é«˜é¢‘å æ¯”çš„åˆ†å¸ƒ
   
2. **complexity_robustness_bar.png**
   - 4 å­å›¾ï¼šè´¨é‡å¯¹æ¯”ã€è¯­ä¹‰é€€åŒ–ã€ä¼ è¾“ç‡ã€å¤æ‚åº¦å¾—åˆ†

3. **complexity_vs_performance.png**
   - 2 å­å›¾ï¼šå¤æ‚åº¦ vs sim_rxã€å¤æ‚åº¦ vs è¯­ä¹‰é€€åŒ–ï¼ˆæ•£ç‚¹å›¾+è¶‹åŠ¿çº¿ï¼‰

---

## ğŸ”§ é‡ç°å®éªŒ

### æ ‡å‡†å®éªŒï¼ˆ150 å¼ å›¾ï¼Œ~40 åˆ†é’Ÿï¼‰

```powershell
python experiments/exp_complexity_robustness.py
```

### å¿«é€Ÿæµ‹è¯•ï¼ˆ30 å¼ å›¾ï¼Œ~8 åˆ†é’Ÿï¼‰

ç¼–è¾‘ `exp_complexity_robustness.py`ï¼š
```python
# åœ¨æ”¶é›†å›¾åƒåæ·»åŠ 
image_paths = image_paths[:30]
```

---

## ğŸ’¬ è®¨è®ºä¸æœªæ¥å·¥ä½œ

### å¼€æ”¾é—®é¢˜1ï¼šå› æœå…³ç³» vs ç›¸å…³æ€§

**å½“å‰å‘ç°ï¼š** ä¸­å¤æ‚åº¦ â†’ é«˜é²æ£’æ€§

**é—®é¢˜ï¼š** æ˜¯å¦å› ä¸ºï¼š
1. å¤æ‚åº¦æœ¬èº«å¯¼è‡´é²æ£’æ€§ï¼Ÿ
2. ä¸­å¤æ‚åº¦å›¾åƒæ°å¥½æ˜¯ VAE/CLIP è®­ç»ƒé›†ä¸»è¦å†…å®¹ï¼Ÿ

**éªŒè¯æ–¹æ³•ï¼š**
- åœ¨å…¶ä»– VAEï¼ˆå¦‚ VQGANï¼‰ä¸Šé‡å¤å®éªŒ
- åœ¨å…¶ä»– CLIP å˜ä½“ï¼ˆViT-L/14ï¼‰ä¸Šé‡å¤

---

### å¼€æ”¾é—®é¢˜2ï¼šå¤æ‚åº¦å®šä¹‰çš„ä¸»è§‚æ€§

**å½“å‰æ–¹æ³•ï¼š** æ‰‹å·¥è®¾è®¡æƒé‡ï¼ˆ0.5, 0.3, 0.2ï¼‰

**é—®é¢˜ï¼š** æƒé‡æ˜¯å¦æœ€ä¼˜ï¼Ÿ

**æ›¿ä»£æ–¹æ¡ˆï¼š**
- å­¦ä¹ æƒé‡ï¼ˆå›å½’ sim_rxï¼‰
- PCA é™ç»´ï¼ˆè‡ªåŠ¨åŠ æƒï¼‰
- ç«¯åˆ°ç«¯å­¦ä¹ å¤æ‚åº¦è¡¨å¾

---

### å¼€æ”¾é—®é¢˜3ï¼šä¸‹æ¸¸ä»»åŠ¡æ³›åŒ–æ€§

**å½“å‰è¯„ä¼°ï¼š** CLIP ç›¸ä¼¼åº¦ï¼ˆé€šç”¨è¯­ä¹‰ï¼‰

**é—®é¢˜ï¼š** å¯¹å…·ä½“ä»»åŠ¡ï¼ˆåˆ†ç±»ã€æ£€æµ‹ï¼‰æ˜¯å¦æˆç«‹ï¼Ÿ

**æ‰©å±•ï¼š**
- åˆ†ç±»ä»»åŠ¡ï¼šTop-1 å‡†ç¡®ç‡ vs å¤æ‚åº¦
- æ£€æµ‹ä»»åŠ¡ï¼šmAP vs å¤æ‚åº¦
- åˆ†å‰²ä»»åŠ¡ï¼šIoU vs å¤æ‚åº¦

---

**å®éªŒå®Œæˆæ—¶é—´ï¼š** 2025-11-25  
**è€—æ—¶ï¼š** 38 åˆ† 28 ç§’  
**ç›¸å…³å®éªŒï¼š** 
- [å®éªŒ1: é‡åŒ–ä¸å™ªå£°](EXP1_RESULTS.md)
- [å®éªŒ2: ä¸ç¡®å®šæ€§é˜ˆå€¼](EXP2_RESULTS.md)  
- [å®éªŒ3: SigmaÃ—Tau è”åˆä¼˜åŒ–](EXP3_RESULTS.md)
**æ•°æ®ä½ç½®ï¼š** `results/complexity_robustness_*.csv`

````
